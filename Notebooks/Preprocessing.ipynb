{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-22T18:44:34.408440Z",
     "start_time": "2023-07-22T18:44:32.660760Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Imports \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import ExcelWriter\n",
    "from pandas import ExcelFile\n",
    "from numpy import diff\n",
    "from scipy.signal import savgol_filter\n",
    "from scipy.interpolate import interp1d\n",
    "from operator import truediv\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-22T18:44:34.438264Z",
     "start_time": "2023-07-22T18:44:34.418914Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Constants \n",
    "\n",
    "# Filepaths for the raw data and the preprocessed data that this code will output\n",
    "FILEPATH_RAW = '../Data_Raw/'\n",
    "FILEPATH_PREPROCESSED = '../Data_Preprocessed/'\n",
    "\n",
    "# Dictionary of the datasets files as values, and names attributed to them as keys\n",
    "NAMES_DATASETS = {\n",
    "    'OD' : 'F0.csv', # Raw optical density data\n",
    "    'FT' : 'F1.csv', # Raw test fluorescence data\n",
    "    'FC' : 'F2.csv'  # Raw control fluorescence data\n",
    "}\n",
    "\n",
    "# Define the names for the final metrics\n",
    "NAMES_FINAL = [\n",
    "    'FT_OD', # Refers to the fluorescence of the test gene normalised by OD\n",
    "    'FC_OD', # Refers to the fluorescence of the control gene normalised by OD\n",
    "    'FT_FC'  # Refers to the fluorescence of the test gene normalised by that of the control gene\n",
    "]\n",
    "\n",
    "# Interpolation parameters\n",
    "INTERPOLATION_POINTS = 750\n",
    "WINDOW_SIZE = 101\n",
    "POLY_ORDER = 2\n",
    "KIND_OF_INTERPOLATION = 'linear'\n",
    "\n",
    "# Stable region inference parameters\n",
    "TIME_BEFORE_MAX_GROWTH = 8 # How much do we allow the window to go before Max Growth.\n",
    "WINDOW_DURATION = 40 # How long do we want the window to be.\n",
    "\n",
    "# Exporting the processed data\n",
    "EXPORT_CSV = True # Whether the output of this code will be saved\n",
    "EXPORT_NAME = '_final_stats.csv' # Suffix of the preprocessed datasets if they are saved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-22T18:44:34.450655Z",
     "start_time": "2023-07-22T18:44:34.441399Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Function to load data \n",
    "\n",
    "def func_load_data(filepath, names):\n",
    "    \"\"\"\n",
    "    Load raw data from csv files into a dictionary.\n",
    "\n",
    "    Args:\n",
    "    filepath (str): The directory path where the data files are stored (defined in Constants).\n",
    "    names (dict): The names of the datasets and the corresponding filenames (defined in Constants).\n",
    "\n",
    "    Returns:\n",
    "    data (dict): The loaded data, where the keys are dataset names and values are DataFrames.\n",
    "    \"\"\"\n",
    "\n",
    "    data_raw = {key: pd.read_csv(filepath + value, index_col=0) for key, value in names.items()}\n",
    "    return data_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-22T18:44:34.496544Z",
     "start_time": "2023-07-22T18:44:34.464267Z"
    },
    "cell_style": "center",
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Function to interpolate, filter, differentiate and normalize \n",
    "\n",
    "def func_IFDN(\n",
    "    data_raw,\n",
    "    names_raw,\n",
    "    interpolation_points,\n",
    "    window_size,\n",
    "    poly_order,\n",
    "    kind_of_interpolation,\n",
    "):\n",
    "\n",
    "    \"\"\"\n",
    "    Preprocess the raw data. This function interpolates, filters, and computes the relevant derivatives of the raw data.\n",
    "\n",
    "    Args:\n",
    "    data_raw (dict): The raw data dictionary (output of func_load_data).\n",
    "    names_raw (dict): The names of the datasets and the corresponding filenames (defined in Constants).\n",
    "    interpolation_points (int): The number of interpolation points (defined in Constants).\n",
    "    window_size (int): The size of the window for the Savitzky-Golay filter (defined in Constants).\n",
    "    poly_order (int): The polynomial order for the Savitzky-Golay filter (defined in Constants).\n",
    "    kind_of_interpolation (str): The type of interpolation to be used (defined in Constants).\n",
    "\n",
    "    Returns:\n",
    "    data_modified (dict): The interpolated and filtered data. Here:\n",
    "        • Interpolated OD\n",
    "        • Filtered OD\n",
    "        • Interpolated test fluorescence\n",
    "        • Filtered test fluorescence\n",
    "        • Interpolated control fluorescence\n",
    "        • Filtered control fluorescence\n",
    "    data_derivatives (dict): The derivatives of the interpolated and filtered data, with relevant normalizations. Here:\n",
    "        • d(OD)/dt\n",
    "        • d(test fluorescence)/dt\n",
    "        • d(control fluorescence)/dt\n",
    "        • (d(test fluorescence)/dt)/(d(OD)/dt)\n",
    "        • (d(control fluorescence)/dt)/(d(OD)/dt)\n",
    "        • (d(test fluorescence)/dt)/(d(test fluorescence)/dt)\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    # Initialise interpolated time array\n",
    "    Time_itp = np.linspace(\n",
    "        float(data_raw['OD'].columns.tolist()[0]), # Interval beginning\n",
    "        float(data_raw['OD'].columns.tolist()[-1]), # Interval end\n",
    "        interpolation_points # This is the number of evenly spaced values within the specified interval\n",
    "    )\n",
    "\n",
    "    # Initialise dataframes for interpolated (itp) and filtered (fil) data\n",
    "    data_modified = {key + suffix: pd.DataFrame(index=data_raw['OD'].index, columns=Time_itp)\n",
    "             for key in names_raw.keys()\n",
    "             for suffix in ['_itp', '_fil']}\n",
    "\n",
    "    # Initialise dataframes for time derived (der), and normalised (Fx_Fy) data\n",
    "    keys = [key + '_der' for key in names_raw.keys()] + ['FT_OD', 'FC_OD', 'FT_FC']\n",
    "    data_derivatives = {key: pd.DataFrame(index=data_raw['OD'].index, columns=Time_itp[1:])\n",
    "                        for key in keys}\n",
    "\n",
    "    # Loop over all the samples (a sample is constituted by the temporal signals acquired for a given microplate well).\n",
    "    for i in range(len(data_raw['OD'])):\n",
    "\n",
    "        # Counter to keep track of the computation progress\n",
    "        progress=np.round(i/len(data_raw['OD']),2)*100\n",
    "        print(f\"{progress:.2f}%\", end=\"\\r\")\n",
    "\n",
    "        # Obtain the time stamps associated with the current sample\n",
    "        time = list(map(float, data_raw['OD'].columns.tolist()))\n",
    "        Nb_nan = data_raw['OD'].iloc[i].isnull().sum() # Number of NaN values because not all data acquisitions are as long as each other\n",
    "        if Nb_nan:\n",
    "            time = time[:-Nb_nan]\n",
    "        time_stamps = np.linspace(time[0], time[-1], interpolation_points)\n",
    "\n",
    "        # Loop over the datasets\n",
    "        for j in names_raw.keys():\n",
    "\n",
    "            # Remove nan values from the current sample\n",
    "            values = data_raw[j].iloc[i]\n",
    "            values_nonan = [value for value in values if not np.isnan(value)]\n",
    "\n",
    "            # Interpolate the raw data\n",
    "            data_modified[j+'_itp'].iloc[i] = interp1d(\n",
    "                time,\n",
    "                values_nonan,\n",
    "                kind=kind_of_interpolation\n",
    "            )(time_stamps) \n",
    "\n",
    "            # Filter the interpolated data\n",
    "            data_modified[j+'_fil'].iloc[i] = savgol_filter(\n",
    "                data_modified[j+'_itp'].iloc[i].tolist(),\n",
    "                window_size,\n",
    "                poly_order)  \n",
    "\n",
    "            # Compute the derivatives of the interpolated data\n",
    "            data_derivatives[j+'_der'].iloc[i] = diff( data_modified[j+'_fil'].iloc[i] ) / diff(time_stamps)\n",
    "\n",
    "        # Compute the normalisations for the differentiated data\n",
    "        data_derivatives['FT_OD'].iloc[i] = np.divide(\n",
    "            data_derivatives['FT_der'].iloc[i].values,\n",
    "            data_derivatives['OD_der'].iloc[i].values,\n",
    "            out=np.zeros_like(data_derivatives['FT_der'].iloc[i]),\n",
    "            where=data_derivatives['OD_der'].iloc[i]!=0\n",
    "        )\n",
    "        data_derivatives['FC_OD'].iloc[i] = np.divide(\n",
    "            data_derivatives['FC_der'].iloc[i].values,\n",
    "            data_derivatives['OD_der'].iloc[i].values,\n",
    "            out=np.zeros_like(data_derivatives['FC_der'].iloc[i]),\n",
    "            where=data_derivatives['OD_der'].iloc[i]!=0\n",
    "        )\n",
    "        data_derivatives['FT_FC'].iloc[i] = np.divide(\n",
    "            data_derivatives['FT_der'].iloc[i].values,\n",
    "            data_derivatives['FC_der'].iloc[i].values,\n",
    "            out=np.zeros_like(data_derivatives['FT_der'].iloc[i]),\n",
    "            where=data_derivatives['FC_der'].iloc[i]!=0\n",
    "        )\n",
    "\n",
    "    return data_modified, data_derivatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-22T18:44:34.535876Z",
     "start_time": "2023-07-22T18:44:34.507123Z"
    },
    "code_folding": [
     0
    ],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# Function to compute the final metrics \n",
    "\n",
    "def func_final_metrics(\n",
    "    data_modified,\n",
    "    data_derivatives,\n",
    "    window_duration,\n",
    "    time_before_max_growth,\n",
    "    names_final\n",
    "):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function selects the window of time with the smallest variance in the normalised differentiated data, \n",
    "    and computes the mean value over this window, which serves as the final metric for each condition of each sample.\n",
    "\n",
    "    Args:\n",
    "    data_modified (dict): The interpolated and filtered data (output of func_IFDN).\n",
    "    data_derivatives (dict): The derivatives of the interpolated and filtered data, with relevant normalizations (output of func_IFDN).\n",
    "    window_duration (int): How long do we want the window to be (defined in Constants).\n",
    "    time_before_max_growth (int): How much do we allow the window to go before maximum growth rate (defined in Constants).\n",
    "    names_final (list): The names of the final datasets to be computed (defined in Constants).\n",
    "\n",
    "    Returns:\n",
    "    data_final_metrics (dict): A dictionary of pandas DataFrames. Each DataFrame contains the mean values over \n",
    "    the window with the smallest variance for each sample and each condition in the 'names_final' list.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialise final computations dataframes which will store the final computed metrics for each sample. \n",
    "    data_final_metrics = {names_final: pd.DataFrame(index=data_derivatives['OD_der'].index,columns=['Mean'])\n",
    "                         for names_final in names_final}\n",
    "\n",
    "    # Loop over all samples\n",
    "    for m in range(len(data_derivatives['OD_der'])):   \n",
    "\n",
    "        # Counter to keep track of the computation progress\n",
    "        progress=np.round(m/len(data_derivatives['OD_der']),2)*100\n",
    "        print(f\"{progress:.2f}%\", end=\"\\r\")\n",
    "\n",
    "        # Define current sample\n",
    "        sample = data_derivatives['OD_der'].index[m]\n",
    "\n",
    "        # Compute growth rate\n",
    "        Growth_Rate = np.divide(data_derivatives['OD_der'].loc[sample].tolist(),\n",
    "                                data_modified['OD_fil'].loc[sample].tolist()[:-1])\n",
    "\n",
    "        # Compute the number of possible time windows\n",
    "        Nb_possible_timewindows = max(1,abs(np.argmax(Growth_Rate) - window_duration))\n",
    "\n",
    "        # Initialize all possible signal windows to store the possible signal windows and their variances.\n",
    "        SignalWindows = {names_final: np.zeros((Nb_possible_timewindows,window_duration)) for names_final in names_final}\n",
    "        Vars          = {names_final: np.zeros(Nb_possible_timewindows) for names_final in names_final}\n",
    "\n",
    "        # Loop over all time windows. For each time window, it loops over conditions to store possible signal windows and \n",
    "        # compute their variances.\n",
    "        for k in range(Nb_possible_timewindows):\n",
    "            # Loop over conditions\n",
    "            for names_final_i in names_final:\n",
    "                # Store possible signal windows\n",
    "                SignalWindows[names_final_i][k] = data_derivatives[names_final_i].loc[sample].tolist()[k:k+window_duration]\n",
    "                # Compute the signal variance over the possible signal windows\n",
    "                Vars[names_final_i][k] = np.var(SignalWindows[names_final_i][k])\n",
    "\n",
    "        # Loop over conditions. For each condition, it finds the best signal window, i.e., the one with minimum variance and \n",
    "        # computes the temporal mean over the relevant window. This mean value is the final metric for the sample under that condition.\n",
    "        for names_final_i in names_final:\n",
    "            # Find the best signal window\n",
    "            Var_MinIdx = list(Vars[names_final_i]).index(min(Vars[names_final_i][-time_before_max_growth:],key=abs))\n",
    "            Best_SignalWindow = data_derivatives[names_final_i].loc[sample].tolist()[Var_MinIdx:Var_MinIdx+window_duration]\n",
    "            # Compute temporal mean over the relevant window\n",
    "            data_final_metrics[names_final_i].loc[sample] = np.mean(Best_SignalWindow)\n",
    "            \n",
    "    return data_final_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-22T18:44:34.555212Z",
     "start_time": "2023-07-22T18:44:34.539525Z"
    },
    "code_folding": [
     0
    ],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# Function to compute the statistics over final metrics \n",
    "\n",
    "def func_stats(\n",
    "    data_raw,\n",
    "    final_metrics,\n",
    "    names_final\n",
    "):\n",
    "\n",
    "    \"\"\"\n",
    "    This function computes the mean and the standard error of the mean (SEM) over replicas \n",
    "    for each unique condition in the dataset. The unique conditions are determined by splitting \n",
    "    the 'OD' index in the raw data. The function assumes that replicas are distinguished by a \n",
    "    '_r' in the index name. The final metrics are then averaged over these replicas.\n",
    "\n",
    "    Args:\n",
    "    final_metrics (dict): A dictionary of pandas DataFrames (output of func_final_metrics).\n",
    "    data_raw (dict): The raw data dictionary (output of func_load_data).\n",
    "    names_final (List[str]): The names of the final datasets to be computed (defined in Constants).\n",
    "\n",
    "    Returns:\n",
    "    data_final_stats (dict): A dictionary of pandas DataFrames. Each DataFrame contains the mean \n",
    "    and SEM of the final metrics for each unique condition and each dataset in the 'names_final' list.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Compute Final Metrics over replica \n",
    "\n",
    "    # Extract unique conditions from sample names by splitting at '_r'\n",
    "    unique_samples = set([var[0] for var in data_raw['OD'].index.str.split('_r')])\n",
    "    \n",
    "    # Initialize dataframes a new dictionary of dataframes to store the statistical results\n",
    "    data_final_stats = {names_final: pd.DataFrame(index=sorted(unique_samples),columns=['Mean','SEM'])\n",
    "                        for names_final in names_final}\n",
    "    \n",
    "    # Loop over all unique conditions\n",
    "    for var in sorted(unique_samples):\n",
    "        \n",
    "        # Loop over each condition to compute and store statistics\n",
    "        for names_final_i in names_final:\n",
    "            \n",
    "            # Find all replicates for a given condition in final_metrics\n",
    "            replicates = final_metrics[names_final_i][final_metrics[names_final_i].index.str.contains(var)]\n",
    "            \n",
    "            # Compute mean and standard error of the mean (SEM) across replicates\n",
    "            mean = replicates.mean(axis=0)[0]\n",
    "            sem = replicates.sem(axis=0)[0]\n",
    "            \n",
    "            # Store mean and SEM in the appropriate dataframe\n",
    "            data_final_stats[names_final_i].loc[var] = mean, sem\n",
    "            \n",
    "    return data_final_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-22T18:44:34.575341Z",
     "start_time": "2023-07-22T18:44:34.558764Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Function to export preprocessed data \n",
    "\n",
    "def func_export(export_csv, export_name, filepath_preprocessed, names_final, stats):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function takes statistics of the preprocessed data \"stats\" and exports them to CSV format, if the 'export_csv' flag is set to True\n",
    "    The name of each CSV file is determined by the corresponding element in 'names_final' and the 'export_name' string.\n",
    "\n",
    "    Args:\n",
    "    export_csv (bool): A flag indicating whether the data should be exported to CSV (defined in Constants).\n",
    "    export_name (str): A string to be appended to the name of each exported file (defined in Constants).\n",
    "    filepath_preprocessed (str): The file path where the exported files will be saved (defined in Constants).\n",
    "    names_final (List[str]): The names of the datasets to be exported (defined in Constants).\n",
    "    stats (Dict[str, pd.DataFrame]): The preprocessed data to be exported (output of func_stats).\n",
    "    \"\"\"\n",
    "    \n",
    "    # Check if the export_csv flag is set to True\n",
    "    if export_csv:\n",
    "        # Loop over each dataset name in names_final\n",
    "        for names_final_i in names_final:\n",
    "            # Save the dataset to a CSV file, with the filename determined by the dataset name and export_name\n",
    "            stats[names_final_i].to_csv(filepath_preprocessed+names_final_i+export_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-22T18:44:34.678160Z",
     "start_time": "2023-07-22T18:44:34.578806Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Load data \n",
    "\n",
    "Data_Raw = func_load_data(\n",
    "    FILEPATH_RAW,\n",
    "    NAMES_DATASETS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-22T18:44:45.655026Z",
     "start_time": "2023-07-22T18:44:34.682966Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.00%\r"
     ]
    }
   ],
   "source": [
    "# Interpolate, Filter, Differentiate and Normalise data  \n",
    "\n",
    "Data_Modified, Data_Derivatives = func_IFDN(\n",
    "    Data_Raw,\n",
    "    NAMES_DATASETS,\n",
    "    INTERPOLATION_POINTS,\n",
    "    WINDOW_SIZE,\n",
    "    POLY_ORDER,\n",
    "    KIND_OF_INTERPOLATION\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-22T18:48:12.323269Z",
     "start_time": "2023-07-22T18:44:45.663039Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.00%\r"
     ]
    }
   ],
   "source": [
    "# Compute final metrics \n",
    "Final_Metrics = func_final_metrics(\n",
    "    Data_Modified,\n",
    "    Data_Derivatives,\n",
    "    WINDOW_DURATION,\n",
    "    TIME_BEFORE_MAX_GROWTH,\n",
    "    NAMES_FINAL\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-22T18:48:13.690539Z",
     "start_time": "2023-07-22T18:48:12.327339Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Compute final statistics \n",
    "Stats = func_stats(\n",
    "    Data_Raw,\n",
    "    Final_Metrics,\n",
    "    NAMES_FINAL\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-22T18:48:13.754276Z",
     "start_time": "2023-07-22T18:48:13.694716Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Export final statistics \n",
    "\n",
    "func_export(\n",
    "    EXPORT_CSV,\n",
    "    EXPORT_NAME,\n",
    "    FILEPATH_PREPROCESSED,\n",
    "    NAMES_FINAL,\n",
    "    Stats\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
